{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from yahoo_finance import Share\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from bn_class import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Hyperparameters\"\"\"\n",
    "num_filt_1 = 15     #Number of filters in first conv layer\n",
    "num_filt_2 = 8      #Number of filters in second conv layer\n",
    "num_filt_3 = 8      #Number of filters in thirs conv layer\n",
    "num_fc_1 = 1024     #Number of neurons in hully connected layer\n",
    "max_iterations = 8000\n",
    "model_num=7         #Number of model used for voting\n",
    "voting_times=3      #Threshold of voting\n",
    "batch_size = 100\n",
    "dropout = 0.5       #Dropout rate in the fully connected layer\n",
    "plot_row = 5        #How many rows do you want to plot in the visualization\n",
    "regularization = 1e-4\n",
    "learning_rate = 2e-3\n",
    "input_norm = False   # Do you want z-score input normalization?\n",
    "np.set_printoptions(threshold=np.inf)#print full array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = \"2330\"\n",
    "datadir = 'data/'+ dataset\n",
    "data_train = np.loadtxt(datadir+'_train_15',delimiter=',')\n",
    "data_test_val = np.loadtxt(datadir+'_test',delimiter=',')\n",
    "data_test=data_test_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = data_train[:,1:]\n",
    "X_test = data_test[:,1:]\n",
    "N = X_train.shape[0]\n",
    "Ntest = X_test.shape[0]\n",
    "D = X_train.shape[1]\n",
    "y_train = data_train[:,0]\n",
    "y_test = data_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "base = np.min(y_train)  #Check if data is 0-based\n",
    "if base != 0:\n",
    "    y_train -=base\n",
    "    y_test -= base\n",
    "\n",
    "if input_norm:\n",
    "    mean = np.mean(X_train,axis=0)\n",
    "    variance = np.var(X_train,axis=0)\n",
    "    X_train -= mean\n",
    "    #The 1e-9 avoids dividing by zero\n",
    "    X_train /= np.sqrt(variance)+1e-9\n",
    "    X_test -= mean\n",
    "    X_test /= np.sqrt(variance)+1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with approximately 1467 epochs\n"
     ]
    }
   ],
   "source": [
    "epochs = np.floor(batch_size*max_iterations / N)\n",
    "print('Train with approximately %d epochs' %(epochs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## place for the input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at model 0\n",
      " Training accuracy at 0 out of 8000 is 0.2\n",
      " Training accuracy at 1000 out of 8000 is 0.952294\n",
      " Training accuracy at 2000 out of 8000 is 0.957798\n",
      " Training accuracy at 3000 out of 8000 is 0.979816\n",
      " Training accuracy at 4000 out of 8000 is 0.988991\n",
      " Training accuracy at 5000 out of 8000 is 0.99633\n",
      " Training accuracy at 6000 out of 8000 is 0.99633\n",
      " Training accuracy at 7000 out of 8000 is 1.0\n",
      "Training at model 1\n",
      " Training accuracy at 0 out of 8000 is 0.8\n",
      " Training accuracy at 1000 out of 8000 is 0.955963\n",
      " Training accuracy at 2000 out of 8000 is 0.954128\n",
      " Training accuracy at 3000 out of 8000 is 0.955963\n",
      " Training accuracy at 4000 out of 8000 is 0.968807\n",
      " Training accuracy at 5000 out of 8000 is 0.990826\n",
      " Training accuracy at 6000 out of 8000 is 0.994495\n",
      " Training accuracy at 7000 out of 8000 is 0.998165\n",
      "Training at model 2\n",
      " Training accuracy at 0 out of 8000 is 0.337615\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.955963\n",
      " Training accuracy at 3000 out of 8000 is 0.957798\n",
      " Training accuracy at 4000 out of 8000 is 0.981651\n",
      " Training accuracy at 5000 out of 8000 is 0.981651\n",
      " Training accuracy at 6000 out of 8000 is 0.994495\n",
      " Training accuracy at 7000 out of 8000 is 0.99633\n",
      "Training at model 3\n",
      " Training accuracy at 0 out of 8000 is 0.159633\n",
      " Training accuracy at 1000 out of 8000 is 0.952294\n",
      " Training accuracy at 2000 out of 8000 is 0.957798\n",
      " Training accuracy at 3000 out of 8000 is 0.963303\n",
      " Training accuracy at 4000 out of 8000 is 0.968807\n",
      " Training accuracy at 5000 out of 8000 is 0.976147\n",
      " Training accuracy at 6000 out of 8000 is 0.985321\n",
      " Training accuracy at 7000 out of 8000 is 0.99633\n",
      "Training at model 4\n",
      " Training accuracy at 0 out of 8000 is 0.201835\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.954128\n",
      " Training accuracy at 3000 out of 8000 is 0.959633\n",
      " Training accuracy at 4000 out of 8000 is 0.961468\n",
      " Training accuracy at 5000 out of 8000 is 0.954128\n",
      " Training accuracy at 6000 out of 8000 is 0.961468\n",
      " Training accuracy at 7000 out of 8000 is 0.972477\n",
      "Training at model 5\n",
      " Training accuracy at 0 out of 8000 is 0.473394\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.952294\n",
      " Training accuracy at 3000 out of 8000 is 0.954128\n",
      " Training accuracy at 4000 out of 8000 is 0.968807\n",
      " Training accuracy at 5000 out of 8000 is 0.970642\n",
      " Training accuracy at 6000 out of 8000 is 0.979816\n",
      " Training accuracy at 7000 out of 8000 is 1.0\n",
      "Training at model 6\n",
      " Training accuracy at 0 out of 8000 is 0.733945\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.955963\n",
      " Training accuracy at 3000 out of 8000 is 0.954128\n",
      " Training accuracy at 4000 out of 8000 is 0.954128\n",
      " Training accuracy at 5000 out of 8000 is 0.963303\n",
      " Training accuracy at 6000 out of 8000 is 0.965138\n",
      " Training accuracy at 7000 out of 8000 is 0.968807\n",
      "history data counts: 287\n",
      "after remove Volume is 0 : 271\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAEKCAYAAAA2Hq27AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81f9274650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_rst=np.zeros((model_num,len(y_test)), dtype=np.float)\n",
    "for xx in xrange(0,model_num):\n",
    "  print(\"Training at model \"+str(xx))\n",
    "  x = tf.placeholder(\"float\", shape=[None, D], name = 'Input_data')\n",
    "  y_ = tf.placeholder(tf.int64, shape=[None], name = 'Ground_truth')\n",
    "  keep_prob = tf.placeholder(\"float\")\n",
    "  bn_train = tf.placeholder(tf.bool)          #Boolean value to guide batchnorm\n",
    "\n",
    "  ## w and b and conv function\n",
    "  def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "  def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "  def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "  def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "  with tf.name_scope(\"Reshaping_data\") as scope:\n",
    "    x_image = tf.reshape(x, [-1,D,1,1])\n",
    "\n",
    "  ## Build the graph\n",
    "  # ewma is the decay for which we update the moving average of the \n",
    "  # mean and variance in the batch-norm layers\n",
    "  with tf.name_scope(\"Conv1\") as scope:\n",
    "    W_conv1 = weight_variable([4, 1, 1, num_filt_1], 'Conv_Layer_1')\n",
    "    b_conv1 = bias_variable([num_filt_1], 'bias_for_Conv_Layer_1')\n",
    "    a_conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "    \n",
    "  with tf.name_scope('Batch_norm_conv1') as scope:\n",
    "      ewma = tf.train.ExponentialMovingAverage(decay=0.99)                  \n",
    "      bn_conv1 = ConvolutionalBatchNormalizer(num_filt_1, 0.001, ewma, True)           \n",
    "      update_assignments = bn_conv1.get_assigner() \n",
    "      a_conv1 = bn_conv1.normalize(a_conv1, train=bn_train) \n",
    "      h_conv1 = tf.nn.relu(a_conv1)\n",
    "    \n",
    "  with tf.name_scope(\"Conv2\") as scope:\n",
    "    W_conv2 = weight_variable([4, 1, num_filt_1, num_filt_2], 'Conv_Layer_2')\n",
    "    b_conv2 = bias_variable([num_filt_2], 'bias_for_Conv_Layer_2')\n",
    "    a_conv2 = conv2d(h_conv1, W_conv2) + b_conv2\n",
    "    \n",
    "  with tf.name_scope('Batch_norm_conv2') as scope:\n",
    "      bn_conv2 = ConvolutionalBatchNormalizer(num_filt_2, 0.001, ewma, True)           \n",
    "      update_assignments = bn_conv2.get_assigner() \n",
    "      a_conv2 = bn_conv2.normalize(a_conv2, train=bn_train) \n",
    "      h_conv2 = tf.nn.relu(a_conv2)\n",
    "      \n",
    "  with tf.name_scope(\"Conv3\") as scope:\n",
    "    W_conv3 = weight_variable([4, 1, num_filt_2, num_filt_3], 'Conv_Layer_3')\n",
    "    b_conv3 = bias_variable([num_filt_3], 'bias_for_Conv_Layer_3')\n",
    "    a_conv3 = conv2d(h_conv2, W_conv3) + b_conv3\n",
    "    \n",
    "  with tf.name_scope('Batch_norm_conv3') as scope:\n",
    "      bn_conv3 = ConvolutionalBatchNormalizer(num_filt_3, 0.001, ewma, True)           \n",
    "      update_assignments = bn_conv3.get_assigner() \n",
    "      a_conv3 = bn_conv3.normalize(a_conv3, train=bn_train) \n",
    "      h_conv3 = tf.nn.relu(a_conv3)\n",
    "\n",
    "  with tf.name_scope(\"Fully_Connected1\") as scope:\n",
    "    W_fc1 = weight_variable([D*num_filt_3, num_fc_1], 'Fully_Connected_layer_1')\n",
    "    b_fc1 = bias_variable([num_fc_1], 'bias_for_Fully_Connected_Layer_1')\n",
    "    h_conv3_flat = tf.reshape(h_conv3, [-1, D*num_filt_3])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "  with tf.name_scope(\"Fully_Connected2\") as scope:\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([num_fc_1, num_classes], stddev=0.1),name = 'W_fc2')\n",
    "    b_fc2 = tf.Variable(tf.constant(0.1, shape=[num_classes]),name = 'b_fc2')\n",
    "    h_fc2 = tf.matmul(h_fc1_drop, W_fc2) + b_fc2   \n",
    "  with tf.name_scope(\"SoftMax\") as scope:\n",
    "      regularizers = (tf.nn.l2_loss(W_conv1) + tf.nn.l2_loss(b_conv1) +\n",
    "                    tf.nn.l2_loss(W_conv2) + tf.nn.l2_loss(b_conv2) + \n",
    "                    tf.nn.l2_loss(W_conv3) + tf.nn.l2_loss(b_conv3) +\n",
    "                    tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(b_fc1) + \n",
    "                    tf.nn.l2_loss(W_fc2) + tf.nn.l2_loss(b_fc2))\n",
    "\n",
    "      loss = tf.nn.sparse_softmax_cross_entropy_with_logits(h_fc2,y_)\n",
    "      cost = tf.reduce_sum(loss) / batch_size\n",
    "      cost += regularization*regularizers\n",
    " \n",
    "  ## define train optimizer##\n",
    "  with tf.name_scope(\"train\") as scope:\n",
    "      tvars = tf.trainable_variables()\n",
    "      #We clip the gradients to prevent explosion\n",
    "      grads = tf.gradients(cost, tvars)\n",
    "      optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "      gradients = zip(grads, tvars)\n",
    "      train_step = optimizer.apply_gradients(gradients)\n",
    "\n",
    "  with tf.name_scope(\"Evaluating_accuracy\") as scope:\n",
    "      correct_prediction = tf.equal(tf.argmax(h_fc2,1), y_)\n",
    "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "  \n",
    "  ## run session and evaluate performance##\n",
    "  perf_collect = np.zeros((3,int(np.floor(max_iterations /100))))\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    step = 0      # Step is a counter for filling the numpy array perf_collect\n",
    "    for i in range(max_iterations):#training process\n",
    "      batch_ind = np.random.choice(N,batch_size,replace=False)\n",
    "      \n",
    "      if i==0:\n",
    "          acc_test_before = sess.run(accuracy, feed_dict={ x: X_test, y_: y_test, keep_prob: 1.0, bn_train : False})\n",
    "      if i%1000 == 0:\n",
    "        #Check training performance\n",
    "        result = sess.run(accuracy,feed_dict = { x: X_train, y_: y_train, keep_prob: 1.0, bn_train : False})\n",
    "        print(\" Training accuracy at %s out of %s is %s\" % (i,max_iterations, result))\n",
    "        step +=1\n",
    "      sess.run(train_step,feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind], keep_prob: dropout, bn_train : True})\n",
    "      \n",
    "            #training process done!\n",
    "    predict=sess.run(tf.argmax(h_fc2,1), feed_dict={ x: X_test, y_: y_test, keep_prob: 1.0, bn_train : False})\n",
    "    total_rst[xx]=predict\n",
    "    \n",
    "    \n",
    "  ## show the graph of voting result\n",
    "rst_arr= np.zeros(len(total_rst[0]), dtype=np.float)\n",
    "for i in xrange(0,len(total_rst[0])):\n",
    "  voting=0\n",
    "  for j in xrange(0,len(total_rst)):\n",
    "    if(total_rst[j,i]==1):\n",
    "        voting+=1\n",
    "  if(voting>voting_times):\n",
    "        rst_arr[i]=1\n",
    "  else:\n",
    "        rst_arr[i]=0\n",
    "print(rst_arr)\n",
    "\n",
    "## get stock price and draw\n",
    "stock = Share('2330.TW') #which stock to evaluate\n",
    "startDay='2015-07-14'\n",
    "endDay='2016-08-19'\n",
    "stock_data = stock.get_historical(startDay,endDay)\n",
    "print 'history data counts:' , len(stock_data)\n",
    "stock_data.reverse() \n",
    "def remove(stock_data):\n",
    "    i = 0\n",
    "    while( i < len(stock_data)):\n",
    "        if (int(stock_data[i].get('Volume')) <= 0):\n",
    "            stock_data.remove(stock_data[i])\n",
    "            i = -1\n",
    "        i += 1\n",
    "    return stock_data\n",
    "\n",
    "stock_data=remove(stock_data)\n",
    "print 'after remove Volume is 0 :', len(stock_data)\n",
    "close_line= np.zeros(len(stock_data), dtype=np.float)\n",
    "for x in xrange(0,len(stock_data)):\n",
    "    close_line[x]=float(stock_data[x].get(\"Close\"))\n",
    "\n",
    "#draw pic\n",
    "plt.figure()\n",
    "new_buy= np.zeros(len(close_line), dtype=np.float)\n",
    "for i in xrange(0,len(rst_arr)):\n",
    "    new_buy[i+9]=rst_arr[i]*close_line[i+9]\n",
    "plt.plot(close_line,label='closePrice',linewidth=5,color=[0,0,1])\n",
    "plt.plot(new_buy, 'ro',label='Buy at',linewidth=1,color=[1,0,0])\n",
    "plt.title(\"When To Buy?(\"+startDay+\"~\"+endDay+\")\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
